{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3e2f34",
   "metadata": {},
   "source": [
    "Join all the different datasets into one big dataset and save it into the desired folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0966fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5acba3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 CSV files total: 6 train, 6 test\n"
     ]
    }
   ],
   "source": [
    "environmental_path_root_folder = \"/mnt/d/desktop/COPERNICUS/Classes/3-semester/ml/species/output/EnvironmentalRasters\"\n",
    "\n",
    "## Craw into every folder and look for .csv files\n",
    "# This will collect full paths to every .csv under the root folder\n",
    "all_csvs = []\n",
    "train_files = []\n",
    "test_files = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(environmental_path_root_folder):\n",
    "    # iterate files in the current directory\n",
    "    for fname in filenames:\n",
    "        if not fname.lower().endswith('.csv'):\n",
    "            continue\n",
    "        fullpath = os.path.join(dirpath, fname)\n",
    "        all_csvs.append(fullpath)\n",
    "        name_lower = fname.lower()\n",
    "        # classify by filename first, then by parent folder name as fallback\n",
    "        if 'train' in name_lower:\n",
    "            train_files.append(fullpath)\n",
    "        elif 'test' in name_lower:\n",
    "            test_files.append(fullpath)\n",
    "        else:\n",
    "            parent = os.path.basename(dirpath).lower()\n",
    "            if 'train' in parent:\n",
    "                train_files.append(fullpath)\n",
    "            elif 'test' in parent:\n",
    "                test_files.append(fullpath)\n",
    "\n",
    "# quick sanity: remove duplicates (if any) while preserving order\n",
    "def dedupe_keep_order(seq):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for x in seq:\n",
    "        if x not in seen:\n",
    "            seen.add(x)\n",
    "            out.append(x)\n",
    "    return out\n",
    "\n",
    "all_csvs = dedupe_keep_order(all_csvs)\n",
    "train_files = dedupe_keep_order(train_files)\n",
    "test_files = dedupe_keep_order(test_files)\n",
    "\n",
    "print(f'Found {len(all_csvs)} CSV files total: {len(train_files)} train, {len(test_files)} test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84572766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file GLC24-PA-train-bioclimatic-average.csv is okay\n",
      "The file GLC24-PA-train-bioclimatic-monthly.csv is okay\n",
      "The file GLC24-PA-train-elevation.csv is okay\n",
      "The file GLC24-PA-train-human-footprint.csv is okay\n",
      "The file GLC24-PA-train-landcover.csv is okay\n",
      "The file GLC24-PA-train-soilgrids.csv is okay\n",
      "The file GLC24-PA-test-bioclimatic-average.csv is okay\n",
      "The file GLC24-PA-test-bioclimatic-monthly.csv is okay\n",
      "The file GLC24-PA-test-elevation.csv is okay\n",
      "The file GLC24-PA-test-human-footprint.csv is okay\n",
      "The file GLC24-PA-test-landcover.csv is okay\n",
      "The file GLC24-PA-test-soilgrids.csv is okay\n"
     ]
    }
   ],
   "source": [
    "## Checking if all the files have SurveyID as its column.\n",
    "for file in train_files:\n",
    "    df = pd.read_csv(file,nrows=0)\n",
    "    #print(df.columns)\n",
    "    if \"surveyId\" in df.columns:\n",
    "        print(f\"The file {os.path.basename(file)} is okay\")\n",
    "    else:\n",
    "        print(f\"NOT OKAY: {os.path.basename(file)}\")\n",
    "        \n",
    "## Test\n",
    "for file in test_files:\n",
    "    df = pd.read_csv(file,nrows=0)\n",
    "    #print(df.columns)\n",
    "    if \"surveyId\" in df.columns:\n",
    "        print(f\"The file {os.path.basename(file)} is okay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd4ed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/desktop/COPERNICUS/Classes/3-semester/ml/species/output/EnvironmentalRasters/Climate/GLC24-PA-test-bioclimatic-monthly.csv'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pop the monthly bioclimatic cause its too big\n",
    "train_files.pop(1)\n",
    "test_files.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee4be912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/d/desktop/COPERNICUS/Classes/3-semester/ml/species/output/EnvironmentalRasters/Climate/GLC24-PA-test-bioclimatic-average.csv',\n",
       " '/mnt/d/desktop/COPERNICUS/Classes/3-semester/ml/species/output/EnvironmentalRasters/Elevation/GLC24-PA-test-elevation.csv',\n",
       " '/mnt/d/desktop/COPERNICUS/Classes/3-semester/ml/species/output/EnvironmentalRasters/HumanFootprint/GLC24-PA-test-human-footprint.csv',\n",
       " '/mnt/d/desktop/COPERNICUS/Classes/3-semester/ml/species/output/EnvironmentalRasters/LandCover/GLC24-PA-test-landcover.csv',\n",
       " '/mnt/d/desktop/COPERNICUS/Classes/3-semester/ml/species/output/EnvironmentalRasters/Soilgrids/GLC24-PA-test-soilgrids.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6956aee",
   "metadata": {},
   "source": [
    "###  Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84db5f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (88987, 19)\n",
      "Shape:(88987, 20)\n",
      "Shape:(88987, 36)\n",
      "Shape:(88987, 37)\n",
      "Shape:(88987, 46)\n",
      "\n",
      "Shape: (88987, 47)\n"
     ]
    }
   ],
   "source": [
    "out_folder = \"/mnt/d/desktop/COPERNICUS/Classes/3-semester/ml/species/output\"\n",
    "out_file = \"train_join.parquet\"\n",
    "\n",
    "result = None\n",
    "\n",
    "for file_path in train_files:\n",
    "    # get basename \n",
    "    basename = os.path.splitext(os.path.basename(file_path))[0].split('-')[-1]\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Set surveyID as index temporarily\n",
    "    df.set_index('surveyId', inplace=True)\n",
    "    \n",
    "    # Create MultiIndex columns (basename, column_name)\n",
    "    df.columns = pd.MultiIndex.from_product([[basename], df.columns])\n",
    "    \n",
    "    # Concatenate incrementally\n",
    "    if result is None:\n",
    "        result = df\n",
    "        print(f\"Shape: {result.shape}\")\n",
    "    else:\n",
    "        result = pd.concat([result, df], axis=1, join='outer')\n",
    "        print(f\"Shape:{result.shape}\")\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del df\n",
    "\n",
    "# Reset index to bring surveyID back as a column\n",
    "result = result.reset_index()\n",
    "\n",
    "print(f\"\\nShape: {result.shape}\")\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "if isinstance(result.columns, pd.MultiIndex):\n",
    "    result.columns = ['_'.join(col).strip() if col[1] else col[0] \n",
    "                      for col in result.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd469b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save as a parquet file\n",
    "result.to_parquet(\n",
    "    os.path.join(out_folder, out_file), \n",
    "    engine='fastparquet'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923aea21",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1830c48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4716, 19)\n",
      "Shape:(4716, 20)\n",
      "Shape:(4716, 36)\n",
      "Shape:(4716, 37)\n",
      "Shape:(4716, 46)\n",
      "\n",
      "Shape: (4716, 47)\n"
     ]
    }
   ],
   "source": [
    "out_folder = \"/mnt/d/desktop/COPERNICUS/Classes/3-semester/ml/species/output\"\n",
    "out_file = \"test_join.parquet\"\n",
    "\n",
    "result = None\n",
    "\n",
    "for file_path in test_files:\n",
    "    # get basename \n",
    "    basename = os.path.splitext(os.path.basename(file_path))[0].split('-')[-1]\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Set surveyID as index temporarily\n",
    "    df.set_index('surveyId', inplace=True)\n",
    "    \n",
    "    # Create MultiIndex columns (basename, column_name)\n",
    "    df.columns = pd.MultiIndex.from_product([[basename], df.columns])\n",
    "    \n",
    "    # Concatenate incrementally\n",
    "    if result is None:\n",
    "        result = df\n",
    "        print(f\"Shape: {result.shape}\")\n",
    "    else:\n",
    "        result = pd.concat([result, df], axis=1, join='outer')\n",
    "        print(f\"Shape:{result.shape}\")\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del df\n",
    "\n",
    "# Reset index to bring surveyID back as a column\n",
    "result = result.reset_index()\n",
    "\n",
    "print(f\"\\nShape: {result.shape}\")\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "if isinstance(result.columns, pd.MultiIndex):\n",
    "    result.columns = ['_'.join(col).strip() if col[1] else col[0] \n",
    "                      for col in result.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0319d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save as a parquet file\n",
    "result.to_parquet(\n",
    "    os.path.join(out_folder, out_file), \n",
    "    engine='fastparquet'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "species",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
